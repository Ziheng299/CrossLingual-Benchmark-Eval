{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e99f621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statement\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from datasets import load_dataset\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "077ddae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to save\n",
    "def write_jsonl(df, output_filename):\n",
    "    with open(output_filename, 'w', encoding='utf-8') as jsonl_file:\n",
    "        for idx, row in df.iterrows():\n",
    "            row_dict = {\n",
    "                \"prompt_sn\": \"\", \n",
    "                \"class1\": row['class1'],\n",
    "                \"class2\": row['class2'],\n",
    "                \"class3\": row['class3'],\n",
    "                \"questions\": row['questions'],\n",
    "                \"ref_answers\": row['ref_answers'],\n",
    "                \"multi_media\": row['multi_media'],\n",
    "                \"history_answers\": row['history_answers'],\n",
    "                \"is_markdown\": row['is_markdown'],\n",
    "                \"tags\": row['tags'],\n",
    "                \"auto_eval_type\": row['auto_eval_type'],\n",
    "                \"param\": row['param'],\n",
    "                \"assign_tag\": row['assign_tag'],\n",
    "                \"prompt_elements\": row['prompt_elements'],\n",
    "                \"question_setter\": row['question_setter'],\n",
    "                \"auto_eval_config\": row['auto_eval_config']\n",
    "            }\n",
    "            json.dump(row_dict, jsonl_file, ensure_ascii=False)\n",
    "            jsonl_file.write(\"\\n\")\n",
    "\n",
    "    print(f\"Data has been successfully saved to {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65783867",
   "metadata": {},
   "source": [
    "## Benchmark for MLogiQA\n",
    "Resources: https://huggingface.co/datasets/Qwen/P-MMEval/viewer/mlogiqa/test?p=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d38bfd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6cbb93e95ec4a699bb7c472d3966c36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a20a54ab8b42e185ccd6d6d0f614ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mlogiqa/test/ar.jsonl:   0%|          | 0.00/110k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f67847d2364b4345b332f064b328d161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mlogiqa/test/en.jsonl:   0%|          | 0.00/76.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03f16c6a987d403da778ae917969ecef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mlogiqa/test/es.jsonl:   0%|          | 0.00/87.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b5f87c9a4d41d68b6979a3df14a57a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mlogiqa/test/fr.jsonl:   0%|          | 0.00/91.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4536ab123ba54edb9bd2eff2d6e0e94b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mlogiqa/test/ja.jsonl:   0%|          | 0.00/83.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66967e51369341acbd1d28a797abcd3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mlogiqa/test/ko.jsonl:   0%|          | 0.00/81.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e393f7f58e34a66b45efd064a634da1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mlogiqa/test/pt.jsonl:   0%|          | 0.00/84.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fe8e7491f9f4124943bc75e5c979d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mlogiqa/test/th.jsonl:   0%|          | 0.00/172k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecabb79de16e42f68d40d1aac3b90de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mlogiqa/test/vi.jsonl:   0%|          | 0.00/95.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c71a9b7eab6944adbfe1e554624a99fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mlogiqa/test/zh.jsonl:   0%|          | 0.00/59.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d6a0c114a44f1a99c27605a5908e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['options', 'id', 'answer', 'question', 'context'],\n",
       "        num_rows: 800\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"Qwen/P-MMEval\", \"mlogiqa\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f811b9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved successfully to mlogiqa_test_en.jsonl\n"
     ]
    }
   ],
   "source": [
    "url = 'https://huggingface.co/datasets/Qwen/P-MMEval/resolve/main/mlogiqa/test/en.jsonl'\n",
    "local_file_path = 'mlogiqa_test_en.jsonl'\n",
    "\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  \n",
    "\n",
    "with open(local_file_path, 'wb') as f:\n",
    "    f.write(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3aa7e986",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://huggingface.co/datasets/Qwen/P-MMEval/resolve/main/mlogiqa/test/zh.jsonl'\n",
    "local_file_path = 'mlogiqa_test_zh.jsonl'\n",
    "\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  \n",
    "\n",
    "with open(local_file_path, 'wb') as f:\n",
    "    f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c9b2bac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'mlogiqa_test_zh.jsonl'\n",
    "mlogiqa_zh = pd.read_json(file_path, lines=True)\n",
    "file_path = 'mlogiqa_test_en.jsonl'\n",
    "mlogiqa_en = pd.read_json(file_path, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d363b37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_mlogiqa_dataset(df, language):\n",
    "    df['class1'] = '中英文评测'\n",
    "    df['class2'] = 'mlogiqa'\n",
    "    df['class3'] = language\n",
    "    \n",
    "    def format_options(options):\n",
    "        option_dict = {\n",
    "            \"A\": [f\"\\\"{options[0]}\\\"\"],\n",
    "            \"B\": [f\"\\\"{options[1]}\\\"\"],\n",
    "            \"C\": [f\"\\\"{options[2]}\\\"\"],\n",
    "            \"D\": [f\"\\\"{options[3]}\\\"\"]\n",
    "        }\n",
    "        formatted_options = '{' + ', '.join([f'\\\"{key}\\\": [{value[0]}]' for key, value in option_dict.items()]) + '}'\n",
    "        return formatted_options\n",
    "    df['questions'] = df.apply(lambda row: [f\"{row['context']} {row['question']} \\n{format_options(row['options'])}\"], axis=1)\n",
    "\n",
    "    answer_map = {0: \"A\", 1: \"B\", 2: \"C\", 3: \"D\"}\n",
    "    df['ref_answers'] = df['answer'].apply(lambda x: [answer_map.get(x, None)])\n",
    "\n",
    "    df['tags'] = df['id'].apply(lambda x: [f\"mlogiqa_{str(x)}\"]) \n",
    "    df['multi_media'] = [[] for _ in range(len(df))]\n",
    "    df['history_answers'] = [None for _ in range(len(df))]\n",
    "    df['is_markdown'] = 1\n",
    "    df['auto_eval_type'] = 0\n",
    "    df['param'] = None\n",
    "    df['assign_tag'] = \"\"\n",
    "    df['prompt_elements'] = [[] for _ in range(len(df))]\n",
    "    df['question_setter'] = \"\"\n",
    "    df['auto_eval_config'] = [{\"evaluator\": {\"name\": \"\", \"extra\": None}} for _ in range(len(df))]\n",
    "    \n",
    "    return df[['class1', 'class2', 'class3', 'questions', 'ref_answers', 'tags', 'multi_media',\n",
    "               'history_answers', 'is_markdown', 'auto_eval_type', 'param', 'assign_tag', 'prompt_elements', \n",
    "               'question_setter', 'auto_eval_config']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9675ccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_en_mlogiqa = transform_mlogiqa_dataset(mlogiqa_en, language = \"en\")\n",
    "transformed_zh_mlogiqa = transform_mlogiqa_dataset(mlogiqa_zh, language = \"zh_cn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3bcac1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully saved to transformed_mlogiqa_data.jsonl\n"
     ]
    }
   ],
   "source": [
    "combined_mlogiqa = pd.concat([transformed_en_mlogiqa, transformed_zh_mlogiqa], ignore_index=True)\n",
    "write_jsonl(combined_mlogiqa, output_filename = 'transformed_mlogiqa_data.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699a9d3c",
   "metadata": {},
   "source": [
    "## Benchmark for PolyMath\n",
    "Resources: https://huggingface.co/datasets/Qwen/PolyMath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46dd3310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_polymath_dataset(df, language):\n",
    "    df['class1'] = '中英文评测'\n",
    "    df['class2'] = 'PolyMath'\n",
    "    df['class3'] = language\n",
    "    df['questions'] = df['question'].apply(lambda x: [x])\n",
    "    df['ref_answers'] = df['answer'].apply(lambda x: [x])  \n",
    "    df['tags'] = df['id'].apply(lambda x: [re.sub(r'-[a-zA-Z]{2}-', '_', x)])\n",
    "    df['multi_media'] = [[] for _ in range(len(df))]\n",
    "    df['history_answers'] = [None for _ in range(len(df))] \n",
    "    df['is_markdown'] = 1  \n",
    "    df['auto_eval_type'] = 0  \n",
    "    df['param'] = None \n",
    "    df['assign_tag'] = \"\"  \n",
    "    df['prompt_elements'] = [[] for _ in range(len(df))]\n",
    "    df['question_setter'] = \"\" \n",
    "    df['auto_eval_config'] = [{\"evaluator\": {\"name\": \"\", \"extra\": None}} for _ in range(len(df))]\n",
    "\n",
    "    # Return the transformed dataframe\n",
    "    return df[['class1', 'class2', 'class3', 'questions', 'ref_answers', 'tags', 'multi_media',\n",
    "               'history_answers', 'is_markdown', 'auto_eval_type', 'param', 'assign_tag', 'prompt_elements', \n",
    "               'question_setter', 'auto_eval_config']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "171bdeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'top': 'en/top.parquet', 'high': 'en/high.parquet', 'medium': 'en/medium.parquet', 'low': 'en/low.parquet'}\n",
    "en_top = pd.read_parquet(\"hf://datasets/Qwen/PolyMath/\" + splits[\"top\"])\n",
    "en_high = pd.read_parquet(\"hf://datasets/Qwen/PolyMath/\" + splits[\"high\"])\n",
    "en_medium = pd.read_parquet(\"hf://datasets/Qwen/PolyMath/\" + splits[\"medium\"])\n",
    "en_low = pd.read_parquet(\"hf://datasets/Qwen/PolyMath/\" + splits[\"low\"])\n",
    "\n",
    "splits = {'top': 'zh/top.parquet', 'high': 'zh/high.parquet', 'medium': 'zh/medium.parquet', 'low': 'zh/low.parquet'}\n",
    "zh_top = pd.read_parquet(\"hf://datasets/Qwen/PolyMath/\" + splits[\"top\"])\n",
    "zh_high = pd.read_parquet(\"hf://datasets/Qwen/PolyMath/\" + splits[\"high\"])\n",
    "zh_medium = pd.read_parquet(\"hf://datasets/Qwen/PolyMath/\" + splits[\"medium\"])\n",
    "zh_low = pd.read_parquet(\"hf://datasets/Qwen/PolyMath/\" + splits[\"low\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf567c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_en_top = transform_polymath_dataset(en_top, language = \"en\")\n",
    "transformed_en_high = transform_polymath_dataset(en_high, language = \"en\")\n",
    "transformed_en_medium = transform_polymath_dataset(en_medium, language = \"en\")\n",
    "transformed_en_low = transform_polymath_dataset(en_low, language = \"en\")\n",
    "\n",
    "transformed_zh_top = transform_polymath_dataset(zh_top, language = \"zh_cn\")\n",
    "transformed_zh_high = transform_polymath_dataset(zh_high, language = \"zh_cn\")\n",
    "transformed_zh_medium = transform_polymath_dataset(zh_medium, language = \"zh_cn\")\n",
    "transformed_zh_low = transform_polymath_dataset(zh_low, language = \"zh_cn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0255f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully saved to transformed_polyMath_data.jsonl\n"
     ]
    }
   ],
   "source": [
    "combined_polymath = pd.concat([transformed_en_top, transformed_en_high, transformed_en_medium, transformed_en_low,\n",
    "                         transformed_zh_top, transformed_zh_high, transformed_zh_medium, transformed_zh_low],\n",
    "                        ignore_index=True)\n",
    "# combined_polymath.head()\n",
    "write_jsonl(combined_polymath, output_filename = 'transformed_polyMath_data.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468741ca",
   "metadata": {},
   "source": [
    "## Benchmark for MMLU\n",
    "Resources: https://huggingface.co/datasets/CohereLabs/Global-MMLU/viewer/en?views%5B%5D=en_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c696612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_mmlu_dataset(df, language):\n",
    "    df['class1'] = '中英文评测'\n",
    "    df['class2'] = 'Global_MMLU'\n",
    "    df['class3'] = language\n",
    "    df['questions'] = df.apply(\n",
    "        lambda row: [f\"{row['question']}\\n{{ \\\"A\\\": [ \\\"{row['option_a']}\\\"], \\\"B\\\": [ \\\"{row['option_b']}\\\"], \\\"C\\\": [ \\\"{row['option_c']}\\\"], \\\"D\\\": [ \\\"{row['option_d']}\\\"] }}\"], axis=1)\n",
    "    df['ref_answers'] = df['answer'].apply(lambda x: [x])  \n",
    "    df['tags'] = df['sample_id'].apply(lambda x: [x]) \n",
    "    df['multi_media'] = [[] for _ in range(len(df))]\n",
    "    df['history_answers'] = [None for _ in range(len(df))] \n",
    "    df['is_markdown'] = 1  \n",
    "    df['auto_eval_type'] = 0  \n",
    "    df['param'] = None \n",
    "    df['assign_tag'] = \"\"  \n",
    "    df['prompt_elements'] = [[] for _ in range(len(df))]\n",
    "    df['question_setter'] = \"\" \n",
    "    df['auto_eval_config'] = [{\"evaluator\": {\"name\": \"\", \"extra\": None}} for _ in range(len(df))]\n",
    "\n",
    "    # Return the transformed dataframe\n",
    "    return df[['class1', 'class2', 'class3', 'questions', 'ref_answers', 'tags', 'multi_media',\n",
    "               'history_answers', 'is_markdown', 'auto_eval_type', 'param', 'assign_tag', 'prompt_elements', \n",
    "               'question_setter', 'auto_eval_config']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a836164b",
   "metadata": {},
   "source": [
    "### Test on Global MMLU\n",
    "~14.3k datastes for each language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d59513e",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'test': 'en/test-00000-of-00001.parquet', 'dev': 'am/dev-00000-of-00001.parquet'}\n",
    "MMLU_en = pd.read_parquet(\"hf://datasets/CohereLabs/Global-MMLU/\" + splits[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49f09a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MMLU_en.columns\n",
    "unique_tags = MMLU_en['subject'].explode().unique()\n",
    "unique_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f6d13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_en_df = transform_mmlu_dataset(MMLU_en, language = \"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff41f7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'test': 'zh/test-00000-of-00001.parquet', 'dev': 'am/dev-00000-of-00001.parquet'}\n",
    "MMLU_cn = pd.read_parquet(\"hf://datasets/CohereLabs/Global-MMLU/\" + splits[\"test\"])\n",
    "transformed_cn_df = transform_mmlu_dataset(MMLU_cn, language = \"zh_cn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561c25b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([transformed_cn_df, transformed_en_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794fcbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_jsonl(combined_df, output_filename = 'transformed_mmlu_data.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1890f0",
   "metadata": {},
   "source": [
    "### Test on Lite MMLU\n",
    "~400 datastes for each language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97680971",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'test': 'en/test-00000-of-00001.parquet', 'dev': 'en/dev-00000-of-00001.parquet'}\n",
    "en_lite = pd.read_parquet(\"hf://datasets/CohereLabs/Global-MMLU-Lite/\" + splits[\"test\"])\n",
    "\n",
    "splits = {'test': 'zh/test-00000-of-00001.parquet', 'dev': 'zh/dev-00000-of-00001.parquet'}\n",
    "zh_lite = pd.read_parquet(\"hf://datasets/CohereLabs/Global-MMLU-Lite/\" + splits[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5853e4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_en_lite = transform_mmlu_dataset(en_lite, language = \"en\")\n",
    "transformed_zh_lite = transform_mmlu_dataset(zh_lite, language = \"zh_cn\")\n",
    "combined_lite = pd.concat([transformed_en_lite, transformed_zh_lite], ignore_index=True)\n",
    "write_jsonl(combined_lite, output_filename = 'transformed_mmlu_lite_data.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e49efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise KeyboardInterrupt(\"Stopping execution here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cf0152",
   "metadata": {},
   "source": [
    "## Benchmark for MCLM\n",
    "Resources: https://huggingface.co/datasets/amphora/MCLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec8a786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "df_imo = pd.read_parquet(\"hf://datasets/amphora/MCLM/m-imo.parquet\")\n",
    "df_math100 = pd.read_parquet(\"hf://datasets/amphora/MCLM/mt-math100.parquet\")\n",
    "df_aime2024 = pd.read_parquet(\"hf://datasets/amphora/MCLM/mt-aime2024.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b51f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e03ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dataset(df, input='imo'):\n",
    "    transformed_data = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        transformed_data.append({\n",
    "            'class1': '中英文评测',\n",
    "            'class2': 'Global_MMLU_IMO',\n",
    "            'class3': 'zh-cn',\n",
    "            'questions': row['zh-cn'], \n",
    "            'ref_answers': row['answer'],\n",
    "            'tags': f'mmlu_{input}_cn_{idx}',  \n",
    "            'is_markdown': '1'\n",
    "        })\n",
    "        \n",
    "        transformed_data.append({  \n",
    "            'class1': '中英文评测',\n",
    "            'class2': 'Global_MMLU_IMO',\n",
    "            'class3': 'en',\n",
    "            'questions': row['en'], \n",
    "            'ref_answers': row['answer'],\n",
    "            'tags':  f'mmlu_{input}_en_{idx}',  \n",
    "            'is_markdown': '1'\n",
    "        })\n",
    "    transformed_df = pd.DataFrame(transformed_data, columns=['class1', 'class2', 'class3', 'questions', 'ref_answers', 'tags', 'is_markdown'])\n",
    "\n",
    "    return transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0411c189",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df_imo = transform_dataset(df_imo)\n",
    "transformed_df_imo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1db7b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_json(df, filename):\n",
    "    data_dict = df.to_dict(orient='records')\n",
    "    \n",
    "    with open(filename, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(data_dict, json_file, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    print(f\"Data has been successfully saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61954f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_json(transformed_df_imo, \"MMLU_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c435ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_jsonl(df, filename):\n",
    "    data_dict = df.to_dict(orient='records')\n",
    "    \n",
    "    with open(filename, 'w', encoding='utf-8') as jsonl_file:\n",
    "        for record in data_dict:\n",
    "            jsonl_file.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "    \n",
    "    print(f\"Data has been successfully saved to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728e7521",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_jsonl(transformed_df_imo, \"transformed_data.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9f37e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df_math100 = transform_dataset(df_math100, input='math100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ad902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df_math100.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cb3799",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df_aime2024 = transform_dataset(df_aime2024, input='aime2024')\n",
    "transformed_df_aime2024.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd2326a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benchmark_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
